{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chapter 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ch4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 간단한 분류 모델 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 털과 날개가 있는냐를 기준으로 포유류와 조류를 구분하는 신경망 모델을 만들어 보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy 라이브러리는 유명한 수치해석동 파이썬 라이브러리 이다. 행렬 조작과 연산에 필수라고 할수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\jiyun lee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[0,0],[1,0],[1,1],[0,0],[0,0],[0,1]]) \n",
    "#[털, 날개] 있으면 1 없으면 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np.array([[1,0,0], #기타\n",
    "                  [0,1,0], #포유류\n",
    "                  [0,0,1], #조류\n",
    "                  [1,0,0],\n",
    "                  [1,0,0],\n",
    "                  [0,0,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [털, 날개] -> [기타, 포유류, 조류]\n",
    "#### [0,0] -> [1,0,0] 기타\n",
    "#### [1,0] -> [0,1,0] 포유류\n",
    "#### [1,1] -> [0,0,1] 조류\n",
    "#### [0,0] -> [1,0,0] 기타\n",
    "#### [0,0] -> [1,0,0] 기타\n",
    "#### [0,1] -> [0,0,1] 조류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([2,3],-1.,1.))\n",
    "b = tf.Variable(tf.zeros([3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +) 가중치 변수 W는 [입력층(특징 수),출력층(레이블 수)]의 구성인 [2,3]으로 설정하고 편향 변수 b는 레이블 수인 3개의 요소를 가진 변수로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = tf.add(tf.matmul(X,W),b)\n",
    "L = tf.nn.relu(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.nn.softmax(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +) 신경망을 통해 나온 출력값을 softmax 함수를 이용하여 사용하기 쉽게 다듬어준다. \n",
    "#### softmax 는 배열 내의 결과값는들 전헤 합이 1이 되도록 만들어 준다 ex) [8.14, 2.27, -6.52] -> [0.53, 0.24, 0.23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(model),axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +) reduce_xxxx 함수는 텐서의 차원을 줄여준다. xxxx 부분이 구체적인 차원 축소 방법을 뜻하고 axis 매개변수로 축소할 차원을 정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1.0348145\n",
      "20 1.0286428\n",
      "30 1.0226768\n",
      "40 1.0167947\n",
      "50 1.011109\n",
      "60 1.0054673\n",
      "70 1.0000067\n",
      "80 0.9946416\n",
      "90 0.98937345\n",
      "100 0.9842555\n"
     ]
    }
   ],
   "source": [
    "for step in range(100):\n",
    "    sess.run(train_op, feed_dict={X: x_data,Y: y_data})\n",
    "    if (step + 1) % 10 ==0:\n",
    "        print(step + 1,sess.run(cost, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### argmax 는 행에서 가장 큰 원소가 위치하는 열의 인덱스를 반환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: [2 1 2 2 2 2]\n",
      "실측값: [0 1 2 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "prediction = tf.argmax(model, axis=1)\n",
    "target = tf.argmax(Y, axis=1)\n",
    "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
    "print('실측값:', sess.run(target, feed_dict={Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 50.00\n"
     ]
    }
   ],
   "source": [
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +) tf.cast함수로 0과 1로 바꾸어 평군을 내면 간단히 정확도를 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 횟수를 아무리 늘려도 정확도가 크게 높아지지 않을 것. 그 이유는 신경망이 한 층밖에 안되기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ch4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 심층 신경망 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다중신경망을 만드는 것은 신경망 모델에 가중치와 편향을 추가하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_uniform([2,10],-1.,1.)) #[특징, 은닉층의 뉴런 수]\n",
    "W2 = tf.Variable(tf.random_uniform([10,3],-1.,1.)) #[은닉층의 뉴런 수, 분류 수]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = tf.Variable(tf.zeros([10])) #은닉층의 뉴런수\n",
    "b2 = tf.Variable(tf.zeros([3])) #분류 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = tf.add(tf.matmul(X,W1),b1)\n",
    "L1 = tf.nn.relu(L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.add(tf.matmul(L1,W2),b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = Y,logits=model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1.4652691\n",
      "20 1.0922796\n",
      "30 0.87732786\n",
      "40 0.7371385\n",
      "50 0.61609536\n",
      "60 0.50270486\n",
      "70 0.4050025\n",
      "80 0.31840667\n",
      "90 0.2517248\n",
      "100 0.20361434\n",
      "예측값: [0 1 2 0 0 2]\n",
      "실측값: [0 1 2 0 0 2]\n",
      "정확도: 100.00\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(100):\n",
    "    sess.run(train_op, feed_dict={X: x_data,Y: y_data})\n",
    "    if (step + 1) % 10 ==0:\n",
    "        print(step + 1,sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "        \n",
    "prediction = tf.argmax(model, axis=1)\n",
    "target = tf.argmax(Y, axis=1)\n",
    "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
    "print('실측값:', sess.run(target, feed_dict={Y: y_data}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
